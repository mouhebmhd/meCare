{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction des Publications et Commentaires de Reddit\n",
    "\n",
    "Dans ce projet, nous nous concentrons sur l'extraction de publications et de commentaires de Reddit en utilisant des techniques de web scraping et d'interaction avec l'API. Reddit est une plateforme riche en contenu généré par les utilisateurs sur divers sujets, ce qui en fait une ressource précieuse pour des applications telles que l'analyse des sentiments, le suivi des tendances et la modélisation de sujets.\n",
    "\n",
    "#### Objectifs\n",
    "- **Collecte de Données** : Récupérer les publications et commentaires de subreddits spécifiques en fonction de critères thématiques (par exemple, r/mentalhealth, r/fitness).\n",
    "- **Traitement des Données** : Nettoyer et prétraiter les données extraites afin de les préparer pour l'analyse.\n",
    "- **Stockage des Données** : Stocker les données collectées dans un format structuré, comme un fichier CSV ou une base de données, pour une analyse ultérieure.\n",
    "\n",
    "#### Outils et Technologies\n",
    "- **Python** : Le langage de programmation principal pour le web scraping et l'interaction avec l'API.\n",
    "- **Requests** : Une bibliothèque pour effectuer des requêtes HTTP, si un scraping supplémentaire est nécessaire.\n",
    "- **Pandas** : Une bibliothèque de manipulation de données pour gérer et analyser les données extraites.\n",
    "\n",
    "#### Mise en Route\n",
    "1. **Configurer l’Environnement** : Installer les bibliothèques nécessaires avec pip (`praw`, `requests`, `pandas`).\n",
    "2. **Obtenir les Identifiants API** : Créer un compte Reddit et enregistrer une application pour obtenir les identifiants API (client ID, secret et user agent).\n",
    "3. **Définir la Logique d’Extraction** : Écrire des fonctions pour extraire les données de subreddits ou de fils spécifiques en fonction de mots-clés ou de catégories.\n",
    "4. **Exécuter le Scraper** : Lancer le script et surveiller le processus de collecte de données.\n",
    "5. **Analyser les Données** : Utiliser Pandas pour analyser les publications et commentaires collectés afin d’en tirer des insights.\n",
    "\n",
    "#### Conclusion\n",
    "Ce projet offre une introduction pratique à l’utilisation de l’API de Reddit et à l’analyse de données avec Python, tout en permettant de manipuler des données issues d’une communauté en ligne dynamique.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:#FBCE60;text-align:center;font-size:30px\"> Scraping Reddit's  Posts And Articles </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation de BeautifulSoup4\n",
    "# BeautifulSoup4 (bs4) est une bibliothèque Python utilisée pour extraire et manipuler des données depuis des fichiers HTML et XML. \n",
    "# Elle est souvent utilisée pour le web scraping en combinant avec des requêtes HTTP pour obtenir le contenu des pages web.\n",
    "!pip install bs4\n",
    "\n",
    "# Installation de Selenium\n",
    "# Selenium est une bibliothèque puissante pour automatiser l'interaction avec les navigateurs web.\n",
    "# Elle est utilisée pour le web scraping dynamique, où l'interaction avec les pages (comme le défilement, les clics ou le remplissage de formulaires) est nécessaire.\n",
    "!pip install selenium\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping Reddit's Health related Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## importing libraries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "from bs4 import BeautifulSoup"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": ".env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
