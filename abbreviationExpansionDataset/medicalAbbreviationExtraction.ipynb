{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"surrey-nlp/PLOD-filtered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  id                                           sentence\n",
      "0  0  Alternatively , fibroblasts were plated sparse...\n",
      "1  1  Study - specific risk ratios ( RRs ) and mean ...\n",
      "2  2  Three faba bean genotypes , Aguadulce ( AD ) ,...\n",
      "3  3  Neurological complications of cancer include d...\n",
      "4  4  Reference values ( RVs ) of each analyte were ...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your DatasetDict is named `dataset_dict`\n",
    "\n",
    "# Function to process each dataset and join tokens into sentences\n",
    "def process_dataset(dataset):\n",
    "    return pd.DataFrame({\n",
    "        'id': dataset['id'],\n",
    "        'sentence': [' '.join(tokens) for tokens in dataset['tokens']]\n",
    "    })\n",
    "\n",
    "# Process each split\n",
    "train_df = process_dataset(ds['train'])\n",
    "validation_df = process_dataset(ds['validation'])\n",
    "test_df = process_dataset(ds['test'])\n",
    "\n",
    "# Merge the DataFrames into a single DataFrame (optional)\n",
    "merged_df = pd.concat([train_df, validation_df, test_df], ignore_index=True)\n",
    "\n",
    "# Display the merged DataFrame\n",
    "print(merged_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Alternatively , fibroblasts were plated sparse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Study - specific risk ratios ( RRs ) and mean ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Three faba bean genotypes , Aguadulce ( AD ) ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Neurological complications of cancer include d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Reference values ( RVs ) of each analyte were ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                                           sentence\n",
       "0  0  Alternatively , fibroblasts were plated sparse...\n",
       "1  1  Study - specific risk ratios ( RRs ) and mean ...\n",
       "2  2  Three faba bean genotypes , Aguadulce ( AD ) ,...\n",
       "3  3  Neurological complications of cancer include d...\n",
       "4  4  Reference values ( RVs ) of each analyte were ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extractAbbrev(element):\n",
    "    try:\n",
    "        # Regex pattern to find fully uppercase words in parentheses\n",
    "        pattern = r'\\(([A-Z]+)\\)'\n",
    "\n",
    "        # Find all matches with their start positions\n",
    "        matches = [(match.group(1), match.start()) for match in re.finditer(pattern, element)]\n",
    "        \n",
    "        # Function to remove HTML tags from a string\n",
    "        def remove_html_tags(text):\n",
    "            return re.sub(r'<[^>]*>', '', text)\n",
    "\n",
    "        # Extract words based on the new condition\n",
    "        result = []\n",
    "        for word, position in matches:\n",
    "            \n",
    "            # Find the preceding content up to the word's position\n",
    "            preceding_text = element[:position].split()\n",
    "            \n",
    "            # Extract words starting with the same letter as the abbreviation\n",
    "            extracted_words = []\n",
    "            for w in reversed(preceding_text):\n",
    "                extracted_words.insert(0,w)  # Insert at the beginning of the list\n",
    "                # Stop extracting if the word doesn't contain the first letter\n",
    "                if w[0].lower() not in word.lower():\n",
    "                    break\n",
    "\n",
    "            result.append((word, [remove_html_tags(item) for item in extracted_words]))  # Remove HTML tags\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return []\n",
    "    \n",
    "    return result\n",
    "def preprocessData(resultsAnnotation):\n",
    "    for index in range(len(resultsAnnotation)):\n",
    "        try :\n",
    "            word = resultsAnnotation[index][0]\n",
    "            listOfWords = resultsAnnotation[index][1]\n",
    "            firstLetter = word[0]\n",
    "            # Ensure listOfWords has words starting with the same letter as the abbreviation\n",
    "            while listOfWords and listOfWords[0][0].lower() != firstLetter.lower():\n",
    "                resultsAnnotation[index][1].pop(0)\n",
    "        except:\n",
    "            continue\n",
    "    return resultsAnnotation\n",
    "import json\n",
    "\n",
    "def string_to_object(string):\n",
    "    try:\n",
    "        return json.loads(string)\n",
    "    except json.JSONDecodeError as e:\n",
    "        raise ValueError(f\"Invalid JSON string: {e}\")\n",
    "def get_surrounding_sentence(text, abbreviation):\n",
    "    try:\n",
    "        # Find the position of the abbreviation in the text\n",
    "        match = re.search(re.escape(abbreviation), text)\n",
    "        if not match:\n",
    "            return None\n",
    "\n",
    "        # Start and end positions of the abbreviation\n",
    "        start, end = match.start(), match.end()\n",
    "\n",
    "        # Find the closest sentence boundaries\n",
    "        before = text[:start].rfind('. ')\n",
    "        before = before if before != -1 else 0\n",
    "        after = text[end:].find('. ')\n",
    "        after = after if after != -1 else len(text)\n",
    "\n",
    "        # Extract the sentence\n",
    "        surrounding_sentence = text[before + 2 : end + after].strip()  # +2 to skip the period and space\n",
    "        return surrounding_sentence\n",
    "    except Exception as e:\n",
    "        print(f\"Error in extracting sentence: {e}\")\n",
    "        return None\n",
    "def string_to_object(string):\n",
    "    try:\n",
    "        return json.loads(string)\n",
    "    except json.JSONDecodeError as e:\n",
    "        raise ValueError(f\"Invalid JSON string: {e}\")\n",
    "def make_valid_json(s):\n",
    "    # Step 1: Replace single quotes around keys with double quotes\n",
    "    s = re.sub(r\"(?<=\\{|,)\\s*'([^']+)'\\s*:\", r'\"\\1\":', s)\n",
    "\n",
    "    # Step 2: Replace single quotes around values with double quotes\n",
    "    s = re.sub(r\":\\s*'([^']*)'\\s*(,|\\})\", r':\"\\1\"\\2', s)\n",
    "\n",
    "    # Step 3: Replace single quotes around list elements with double quotes\n",
    "    s = re.sub(r\"\\[\\s*'([^']*)'\\s*(?:,|\\])\", lambda m: f'[\"{m.group(1)}\"' if m.group(0)[-1] == ']' else f'[\"{m.group(1)}\",', s)\n",
    "    s = re.sub(r'\",\\s*\\'([^\\']*)\\'\\s*\\]', r'\", \"\\1\"]', s)\n",
    "\n",
    "    # Step 4: Remove stray single quotes that might exist\n",
    "    s = s.replace(\"'\", '\"')\n",
    "\n",
    "    return s\n",
    "def row_to_object(row):\n",
    "    # Split the expansion into a list of words\n",
    "    expansion_words = row['expansion']\n",
    "    # Create the object\n",
    "    obj = {\n",
    "        'abbreviation': row['abbreviation'],\n",
    "        'expansion': expansion_words,\n",
    "        'sentence': row['sentence']\n",
    "    }\n",
    "    # Convert to string\n",
    "    return str(obj)\n",
    "import json\n",
    "\n",
    "def fix_json_format(string):\n",
    "    # Step 1: Fix the quote marks for JSON compliance (ensure double quotes)\n",
    "    string = string.replace(\"'\", '\"')  # Replaces single quotes with double quotes\n",
    "    \n",
    "    # Step 2: Check if the string ends correctly with a closing square bracket if needed\n",
    "    if string.endswith(\"]]\"):\n",
    "        string = string[:-2] + \"]\"  # Fix the extra closing square brackets\n",
    "    \n",
    "    # Step 3: Ensure the sentence field ends correctly (if needed)\n",
    "    if ',\"sentence\"' in string:\n",
    "        string = string.replace(',\"sentence\"', '],\"sentence\"')  # Correct position of sentence\n",
    "    \n",
    "    try:\n",
    "        return json.loads(string)  # Try to parse it into a Python object\n",
    "    except json.JSONDecodeError as e:\n",
    "        raise ValueError(f\"Invalid JSON string: {e}\")\n",
    "import codecs\n",
    "\n",
    "def remove_escape_characters(input_string):\n",
    "    # Remove escape sequences and non-ASCII characters (or any specific unwanted characters)\n",
    "    cleaned_string = re.sub(r'\\\\x[0-9A-Fa-f]{2}', '', input_string)  # Removing hex escape sequences like \\\\x82\n",
    "    cleaned_string = re.sub(r'[^\\x00-\\x7F]+', '', cleaned_string)  # Removing non-ASCII characters (like Ã³)\n",
    "    \n",
    "    return cleaned_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_surrounding_sentence(text, abbreviation):\n",
    "    try:\n",
    "        # Find the position of the abbreviation in the text\n",
    "        match = re.search(re.escape(abbreviation), text)\n",
    "        if not match:\n",
    "            return None\n",
    "\n",
    "        # Start and end positions of the abbreviation\n",
    "        start, end = match.start(), match.end()\n",
    "\n",
    "        # Find the closest sentence boundaries\n",
    "        before = text[:start].rfind('. ')\n",
    "        before = before if before != -1 else 0\n",
    "        after = text[end:].find('. ')\n",
    "        after = after if after != -1 else len(text)\n",
    "\n",
    "        # Extract the sentence\n",
    "        surrounding_sentence = text[before + 2 : end + after].strip()  # +2 to skip the period and space\n",
    "        return surrounding_sentence\n",
    "    except Exception as e:\n",
    "        print(f\"Error in extracting sentence: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "for i in range(len(merged_df)):\n",
    "    try:\n",
    "        # Process the current sentence and extract abbreviations\n",
    "        sentence = merged_df.iloc[i][\"sentence\"].replace('( ', \"(\").replace(' )', \")\")\n",
    "        extracted_abbreviations = preprocessData(extractAbbrev(sentence))\n",
    "        \n",
    "        for element in extracted_abbreviations:\n",
    "            # Check that both abbreviation and expansion are valid\n",
    "            if len(element[0]) > 1 and len(element[1]) > 1:\n",
    "                # Retrieve the sentence where the abbreviation appears\n",
    "                surrounding_sentence = get_surrounding_sentence(sentence, element[0])\n",
    "                if surrounding_sentence:\n",
    "                    print(f\"Sentence: {surrounding_sentence}\")\n",
    "                    print(f\"Abbreviation: {element[0]}, Expansion: {element[1]}\")\n",
    "                    \n",
    "                    # Append the abbreviation, expansion, and extracted sentence to the results\n",
    "                    results.append({\n",
    "                        \"abbreviation\": element[0],\n",
    "                        \"expansion\": element[1],\n",
    "                        \"sentence\": surrounding_sentence\n",
    "                    })\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing row {i}: {e}\")\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "results=pd.DataFrame(results)\n",
    "results.to_json(\"../abbreviationExpansionDataset/abbreviationsDataset.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['abbreviation', 'expansion', 'sentence'], dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_json(\"../abbreviationExpansionDataset/abbreviationsDataset.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Function to convert row to desired string format\n",
    "def row_to_object(row):\n",
    "    # Split the expansion into a list of words\n",
    "    expansion_words = (row['expansion'])\n",
    "    # Create the object\n",
    "    obj = {\n",
    "        'abbreviation': row['abbreviation'],\n",
    "        'expansion': expansion_words,\n",
    "        'sentence': row['sentence']\n",
    "    }\n",
    "    # Convert to string\n",
    "    return str(obj)\n",
    "\n",
    "# Apply the function to each row\n",
    "df['object_string'] = df.apply(row_to_object, axis=1)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df[['object_string']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=[]\n",
    "for i in range(len(df)):\n",
    "    results.append(df.iloc[i][\"object_string\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"./abbreviationsDataset.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "dx=pd.read_csv(\"plos/valid.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ABSTRACT_ID', 'TEXT', 'LOCATION', 'LABEL'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dx.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_row(row):\n",
    "    abbreviation_word = row[\"TEXT\"].split(\" \")[row[\"LOCATION\"]]\n",
    "    abbreviation = abbreviation_word.upper()\n",
    "    \n",
    "    # Generate the expansion with proper capitalization\n",
    "    expansion = [\n",
    "        word.capitalize() for word in row[\"LABEL\"].split(\" \")\n",
    "    ]\n",
    "    \n",
    "    # Replace the abbreviation in the sentence with the expanded form\n",
    "    expanded_form = f\"{' '.join(expansion)} ({abbreviation})\"\n",
    "    sentence = row[\"TEXT\"].replace(abbreviation_word, expanded_form)\n",
    "    \n",
    "    return {\n",
    "        \"abbreviation\": abbreviation,\n",
    "        \"expansion\": expansion,\n",
    "        \"sentence\": sentence\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=[]\n",
    "for i in range(600000,len(dx)):\n",
    "    item=row_to_object(process_row(dx.iloc[i]))\n",
    "    results.append(item)\n",
    "    print(f\"processing row {i} over {(len(dx))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=pd.DataFrame(results)\n",
    "results.to_csv(\"abbreviationsList10.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "data=pd.read_csv(\"abbreviationsList10.csv\")\n",
    "results=[]\n",
    "for i in range(len(data)):\n",
    "    item=make_valid_json(data.iloc[i,1])\n",
    "    results.append(item)\n",
    "    print(f\"processing item {i} over {len(data)}\")\n",
    "results=pd.DataFrame(results)\n",
    "results.to_csv(\"fragment11.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "data1=pd.read_json(\"abbreviationsAnnotated.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
